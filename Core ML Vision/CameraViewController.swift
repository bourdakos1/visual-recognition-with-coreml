/**
 * Copyright IBM Corporation 2017, 2018
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 **/

import UIKit
import AVFoundation
// This app also uses extensions from `Supporting Files/VisualRecognition+Extensions.swift`.
import VisualRecognitionV3

struct VisualRecognitionConstants {
    static let modelIds = ["YOUR_MODEL_ID"]
    static let version = "2018-07-24"
}

class CameraViewController: UIViewController {
    
    // MARK: - IBOutlets
    
    @IBOutlet var cameraView: UIView!
    @IBOutlet var imageView: UIImageView!
    @IBOutlet var noCameraView: UIView!
    @IBOutlet var captureButton: UIButton!
    @IBOutlet var closeButton: UIButton!
    @IBOutlet var updateModelButton: UIButton!
    @IBOutlet var choosePhotoButton: UIButton!
    
    // MARK: - Variable Declarations
    
    let visualRecognition: VisualRecognition = {
        guard let path = Bundle.main.path(forResource: "Credentials", ofType: "plist") else {
            // Please create a Credentials.plist file with your Visual Recognition credentials.
            fatalError()
        }
        guard let apiKey = NSDictionary(contentsOfFile: path)?["apikey"] as? String else {
            // No Visual Recognition API key found. Make sure you add your API key to the Credentials.plist file.
            fatalError()
        }
        /*
         `easyInit` is not part of the Watson SDK.
         `easyInit` is a convenient extension that tries to detect whether the supplied apiKey is:
         - a Visual Recognition instance created before May 23, 2018
         - a new IAM API key
         It then returns the properly initialized VisualRecognition instance.
         */
        return VisualRecognition.easyInit(apiKey: apiKey, version: VisualRecognitionConstants.version)
    }()
    
    let photoOutput = AVCapturePhotoOutput()
    lazy var captureSession: AVCaptureSession? = {
        guard let backCamera = AVCaptureDevice.default(for: .video),
            let input = try? AVCaptureDeviceInput(device: backCamera) else {
                return nil
        }
        
        let captureSession = AVCaptureSession()
        captureSession.sessionPreset = .high
        captureSession.addInput(input)
        
        if captureSession.canAddOutput(photoOutput) {
            captureSession.addOutput(photoOutput)
            let previewLayer = AVCaptureVideoPreviewLayer(session: captureSession)
            previewLayer.frame = view.bounds
            // `.resize` allows the camera to fill the screen on the iPhone X.
            previewLayer.videoGravity = .resize
            previewLayer.connection?.videoOrientation = .portrait
            cameraView.layer.addSublayer(previewLayer)
            return captureSession
        }
        return nil
    }()
    
    // MARK: - Override Functions
    
    override func viewDidLoad() {
        super.viewDidLoad()
        captureSession?.startRunning()
        resetUI()
    }
    
    override func viewDidAppear(_ animated: Bool) {
        super.viewDidAppear(animated)
        for modelId in VisualRecognitionConstants.modelIds {
            /*
             `checkLocalModelStatus` is not part of the Watson SDK.
             `checkLocalModelStatus` is a convenient extension that checks if the local model
             is up to date. The actual SDK makes this check as well in `updateLocalModel`.
             However, we perfom this check purely for UI purposes.
             */
            visualRecognition.checkLocalModelStatus(classifierID: modelId) { modelUpToDate in
                if !modelUpToDate {
                    self.updateLocalModel(id: modelId)
                }
            }
        }
    }
    
    // MARK: - Methods
    
    func updateLocalModel(id modelId: String) {
        let failure = { (error: Error) in
            DispatchQueue.main.async {
                self.modelUpdateFail(modelId: modelId, error: error)
                SwiftSpinner.hide()
            }
        }
        
        let success = {
            DispatchQueue.main.async {
                SwiftSpinner.hide()
            }
        }
        // The spinner can only be hailed after viewDidAppear.
        SwiftSpinner.show("Compiling model...")
        visualRecognition.updateLocalModel(classifierID: modelId, failure: failure, success: success)
    }
    
    func presentPhotoPicker(sourceType: UIImagePickerControllerSourceType) {
        let picker = UIImagePickerController()
        picker.delegate = self
        picker.sourceType = sourceType
        present(picker, animated: true)
    }
    
    func classifyImage(_ image: UIImage, localThreshold: Double = 0.0) {
        showResultsUI(for: image)
        
        let failure = { (error: Error) in
            DispatchQueue.main.async {
                self.showAlert("Could not classify image", alertMessage: error.localizedDescription)
                self.resetUI()
            }
        }
        
        visualRecognition.classifyWithLocalModel(image: image, classifierIDs: VisualRecognitionConstants.modelIds, threshold: localThreshold, failure: failure) { classifiedImages in
            
            // Make sure that an image was successfully classified.
            guard let classifiedImage = classifiedImages.images.first else {
                return
            }
            
            // Update UI on main thread
            DispatchQueue.main.async {
                // Push the classification results of all the provided models to the ResultsTableView.
                self.push(results: classifiedImage.classifiers)
            }
        }
    }
    
    func dismissResults() {
        push(results: [], position: .closed)
    }
    
    func push(results: [VisualRecognitionV3.ClassifierResult], position: PulleyPosition = .partiallyRevealed) {
        guard let drawer = pulleyViewController?.drawerContentViewController as? ResultsTableViewController else {
            return
        }
        drawer.classifications = results
        pulleyViewController?.setDrawerPosition(position: position, animated: true)
        drawer.tableView.reloadData()
    }
    
    func showResultsUI(for image: UIImage) {
        imageView.image = image
        imageView.isHidden = false
        noCameraView.isHidden = true
        closeButton.isHidden = false
        captureButton.isHidden = true
        choosePhotoButton.isHidden = true
        updateModelButton.isHidden = true
    }
    
    func resetUI() {
        if captureSession != nil {
            noCameraView.isHidden = true
            imageView.isHidden = true
            captureButton.isHidden = false
        } else {
            imageView.image = UIImage(named: "Background")
            noCameraView.isHidden = false
            imageView.isHidden = false
            captureButton.isHidden = true
        }
        
        closeButton.isHidden = true
        choosePhotoButton.isHidden = false
        updateModelButton.isHidden = false
        dismissResults()
    }
    
    // MARK: - IBActions
    
    @IBAction func capturePhoto() {
        photoOutput.capturePhoto(with: AVCapturePhotoSettings(), delegate: self)
    }
    
    @IBAction func updateModel(_ sender: Any) {
        for modelId in VisualRecognitionConstants.modelIds {
            updateLocalModel(id: modelId)
        }
    }
    
    @IBAction func presentPhotoPicker() {
        let picker = UIImagePickerController()
        picker.delegate = self
        picker.sourceType = .photoLibrary
        present(picker, animated: true)
    }
    
    @IBAction func reset() {
        resetUI()
    }
}

// MARK: - Error Handling

extension CameraViewController {
    func showAlert(_ alertTitle: String, alertMessage: String) {
        let alert = UIAlertController(title: alertTitle, message: alertMessage, preferredStyle: UIAlertControllerStyle.alert)
        alert.addAction(UIAlertAction(title: "Dismiss", style: UIAlertActionStyle.default, handler: nil))
        self.present(alert, animated: true, completion: nil)
    }
    
    func modelUpdateFail(modelId: String, error: Error) {
        let error = error as NSError
        var errorMessage = ""
        
        // 0 = probably wrong api key
        // 404 = probably no model
        // -1009 = probably no internet
        
        switch error.code {
        case 0:
            errorMessage = "Please check your Visual Recognition API key in `Credentials.plist` and try again."
        case 404:
            errorMessage = "We couldn't find the model with ID: \"\(modelId)\""
        case 500:
            errorMessage = "Internal server error. Please try again."
        case -1009:
            errorMessage = "Please check your internet connection."
        default:
            errorMessage = "Please try again."
        }
        
        // TODO: Do some more checks, does the model exist? is it still training? etc.
        // The service's response is pretty generic and just guesses.
        
        showAlert("Unable to download model", alertMessage: errorMessage)
    }
}

// MARK: - UIImagePickerControllerDelegate

extension CameraViewController: UIImagePickerControllerDelegate, UINavigationControllerDelegate {
    func imagePickerController(_ picker: UIImagePickerController, didFinishPickingMediaWithInfo info: [String: Any]) {
        picker.dismiss(animated: true)
        
        guard let image = info[UIImagePickerControllerOriginalImage] as? UIImage else {
            return
        }
        
        classifyImage(image)
    }
}

// MARK: - AVCapturePhotoCaptureDelegate

extension CameraViewController: AVCapturePhotoCaptureDelegate {
    func photoOutput(_ output: AVCapturePhotoOutput, didFinishProcessingPhoto photo: AVCapturePhoto, error: Error?) {
        if let error = error {
            print(error.localizedDescription)
            return
        }
        
        guard let photoData = photo.fileDataRepresentation(),
            let image = UIImage(data: photoData) else {
                return
        }
        
        classifyImage(image)
    }
}
